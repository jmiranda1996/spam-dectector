{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ydMqi7-jc3z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "mQ0E9UDGkXL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EXPORT_DIR = pathlib.Path('/content/')\n",
        "DATASET_CSV_PATH = EXPORT_DIR / 'trainspam.csv'\n",
        "TRAINING_DATA_PATH = EXPORT_DIR / 'spam-training-data.pkl'"
      ],
      "metadata": {
        "id": "2eYGN-JYkYFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(DATASET_CSV_PATH, on_bad_lines='skip', sep = ';')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "9KVlebjckfeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['text'].astype(str).tolist()\n",
        "labels = df['cate'].tolist()"
      ],
      "metadata": {
        "id": "WHBdKJe0kpIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_legend = {'False': 0, 'True': 1}\n",
        "labels_legend_inverted = {f\"{v}\":k for k,v in labels_legend.items()}"
      ],
      "metadata": {
        "id": "qZiGuxYVkrss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_as_int =  [labels_legend[str(x)] for x in labels]\n",
        "print(labels_legend_inverted)"
      ],
      "metadata": {
        "id": "2K7cZDk2kthS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_NUM_WORDS=280\n",
        "MAX_SEQUENCE_LENGTH = 280\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y = to_categorical(np.asarray(labels_as_int))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "G5LtOYUyk2BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = {\n",
        "    'X_train': X_train,\n",
        "    'X_test': X_test,\n",
        "    'y_train': y_train,\n",
        "    'y_test': y_test,\n",
        "    'max_words': MAX_NUM_WORDS,\n",
        "    'max_sequence': MAX_SEQUENCE_LENGTH,\n",
        "    'legend': labels_legend,\n",
        "    'labels_legend_inverted': labels_legend_inverted,\n",
        "    \"tokenizer\": tokenizer,\n",
        "}"
      ],
      "metadata": {
        "id": "sKXBpy-plSBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(TRAINING_DATA_PATH, 'wb') as f:\n",
        "    pickle.dump(training_data, f)"
      ],
      "metadata": {
        "id": "x-rrFP7klVA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {}\n",
        "\n",
        "with open(TRAINING_DATA_PATH, 'rb') as f:\n",
        "    data = pickle.load(f)"
      ],
      "metadata": {
        "id": "lX8DevZ4ln9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = data['X_test']\n",
        "X_train = data['X_train']\n",
        "y_test = data['y_test']\n",
        "y_train = data['y_train']\n",
        "labels_legend_inverted = data['labels_legend_inverted']\n",
        "legend = data['legend']\n",
        "max_sequence = data['max_sequence']\n",
        "max_words = data['max_words']\n",
        "tokenizer = data['tokenizer']\n",
        "print(X_train)"
      ],
      "metadata": {
        "id": "EaF6DYKQlpnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NUM_WORDS, embed_dim, input_length=X_train.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "1gNdPvp7lrSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('model_weights.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min')"
      ],
      "metadata": {
        "id": "jqio5S3Klrfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 5\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, verbose=1, epochs=epochs, callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "5qilKYb6lwQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_EXPORT_PATH = EXPORT_DIR / 'spam-model.h5'\n",
        "model.save(str(MODEL_EXPORT_PATH))\n",
        "MODEL_EXPORT_PATH = EXPORT_DIR / 'spam-model'\n",
        "model.save(str(MODEL_EXPORT_PATH))"
      ],
      "metadata": {
        "id": "bMkEQpCXlyvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "static_model = Sequential()\n",
        "static_model.add(Embedding(MAX_NUM_WORDS, embed_dim, input_length=X_train.shape[1]))\n",
        "static_model.add(SpatialDropout1D(0.4))\n",
        "static_model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.3))\n",
        "static_model.add(Dense(2, activation='softmax'))\n",
        "static_model.load_weights('model_weights.h5')\n",
        "static_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "static_model.save('spam-model')"
      ],
      "metadata": {
        "id": "-dK0re4sl5nS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}